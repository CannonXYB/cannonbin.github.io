<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>浙大高分子炮斌网页</title>
    <link rel="icon" href="./images/椰子加农炮.png">
    <link rel="stylesheet" href="css/reset.css">
    <link rel="stylesheet" href="css/代码动态.css">
</head>

<body>
    <div class="header-box">
        <div class="header">
            <div class="layout">
                <div class="logol">
                    <a href="#" target="_blank">
                        <img src="./images/logo.png" alt="">
                    </a>
                </div>
                <div class="searchr">
                    <div class="links">
                        <a href="#">ENGLISH</a>
                        <a href="#">中文网</a>
                    </div>
                    <div class="search">
                        <input type="text" name="keyboard" placeholder="这是炮斌独家网站">
                        <button type="submit">
                            <img src="./images/search.png" alt="">
                        </button>
                    </div>
                </div>
            </div>
        </div>
        <!---->
        <div class="nav">
            <div class="layout">
                <ul>
                    <li>
                        <a href="index.html" target="_self">个人简历</a>
                    </li>
                    <li>
                        <a href="学习仓库.html" target="_self">学习仓库</a>
                    </li>
                    <li>
                        <a href="建模动态.html" target="_self">建模动态</a>
                    </li>
                    <li>
                        <a href="#" target="_self">代码动态</a>
                    </li>
                    <li>
                        <a href="所获荣誉.html" target="_self">所获荣誉</a>
                    </li>
                    <li>
                        <a href="学术研究.html" target="_self">学术研究</a>
                    </li>
                </ul>
            </div>
        </div>
    </div>

    <!---->
    <div class="content" name="disableCopyPaste">
        <h3>均值移除，标准化：</h3>
        <br>
        <p class="explain">
            <h4>&emsp;解说</h4>
        看相似度，让样本矩阵变成均值为0，标准差为1的数据集合。<br>
        如果有一列特征值表示<br>
        #均值移除，标准化：年龄 17 20 23<br>
        mean = (17 + 20 + 23)/3 = 20<br>
        a1 = -3<br>
        b1 = 0<br>
        c1 = 3<br>
        s1 = std(a1,b1,c1)<br>
        print(a1/s1, b1/s1, c1/s1)<br>
        <br>
        import numpy as np<br>
        import sklearn.preprocessing as sp<br>
        # scale函数用于对函数进行预处理，实现均值移除<br>
        # array是原数组，A为array均值移除后的效果<br>
        A = sp.scale(array)<br>
        </p>
        <br>
        <h4>对样本矩阵的说明：一行一样本，一列一特征</h4>
        <br>
        <p class="code">
            <h4>&emsp;举例</h4>
            import numpy as np<br>
            import sklearn.preprocessing as sp<br>
            raw_samples = np.array([<br>
            [17.,100.,4000.],<br>
            [20.,80.,5000.],<br>
            [23.,75.,5500.]<br>
            ])<br>
            std_samples = sp.scale(raw_samples)<br>
            print(std_samples)<br>
            print(std_samples.mean(axis=0)) #求均值：0<br>
            print(std_samples.std(axis=0)) #求标准差:1<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>范围缩放：把特征值放到[0,1],最小是0，最大是1：</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        minmax缩放器：mms = sp.MinMaxScaler(feature_range=(0,1))<br>
        调用mms对象：result = mms.fit_transform(原始数据)<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import sklearn.preprocessing as sp<br>
        raw_samples = np.array([<br>
        [17.,100.,4000.],<br>
        [20.,80.,5000.],<br>
        [23.,75.,5500.]<br>
        ])<br>
        mms = sp.MinMaxScaler(feature_range=(0,1))<br>
        result = mms.fit_transform(raw_samples)<br>
        print(result)<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>归一化：当每个特征值的占比更加重要的时候，每行进行归一化</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        # array 原始样本矩阵<br>
        # norm 范数：<br>
        # l1 - l1 范数，向量中每个元素的绝对值之和<br>
        # l2 - l2 范数，向量中每个元素平方和之和<br>
        #返回归一化预处理后的样本矩阵<br>
        sp.normalize(array, norm='l1')<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import sklearn.preprocessing as sp<br>
        ary = np.array([[10,21,5],<br>
                        [2,4,1],<br>
                        [11,18,18]])<br>
        result = sp.normalize(ary,norm='l1')<br>
        print(result)<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>二值化：图片像素编码，事先要给定阈值</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        # 给出阈值，获取二值化器<br>
        bin = sp.Binarizer(threshold = 阈值)<br>
        # 调用transform方法对原始样本矩阵进行二值化预处理操作<br>
        result = bin.transform(原始图片样本转化的矩阵)<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import sklearn.preprocessing as sp<br>
        ary = np.array([[10,21,5],<br>
        [2,4,1],<br>
        [11,18,18]])<br>
        bin = sp.Binarizer(threshold = 10)<br>
        result = bin.transform(ary)<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>独热编码（One-hot Encoding）：为样本特征的每个值编码</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说<br>
        两个数&emsp; 三个数 &emsp;四个数<br>
        1（第0）&emsp; 3（第2）&emsp; 2（第5）<br>
        7（第1）&emsp; 5（第3）&emsp; 4（第6）<br>
        1&emsp;&emsp;&emsp;&emsp; 8（第4）&emsp; 6（第7）<br>
        7&emsp;&emsp;&emsp;&emsp; 3&emsp;&emsp;&emsp;&emsp; 9（第8）<br>
        转化<br>
        1~ 10 3~ 100 2~ 1000<br>
        7~ 01 5~ 010 4~ 0100<br>
        8~ 001 6~ 0010<br>
        9~ 0001
        得到 使用场景：计算相似度<br>
        101001000<br>
        010100100<br>
        100010010<br>
        011000001<br></h4>

        # 创建一个独热编码器：<br>
        # sparse： 是否采用紧缩格式 ，即稀疏矩阵<br>
        # dtype： 数据类型<br>
        ohe = sp.OneHotEncoder(sparse = ,dtype = ) 训练得到编码字典,升级后变成了sparse_output<br>
        #对原始样本矩阵进行处理，返回独热编码后的样本矩阵<br>
        encoder_dict = ohe.fit(原始样本矩阵)<br>
        result = ohe.fit_transform(原始样本矩阵)<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import sklearn.preprocessing as sp<br>
        samples = np.array([[1,3,2],<br>
        [7,5,4],<br>
        [1,8,6],<br>
        [7,3,9]])<br>
        ohe = sp.OneHotEncoder(sparse_output = True ,dtype = 'int32')<br>
        result = ohe.fit_transform(samples)<br>
        print(result, type(result))<br>
        </p>

        <h4>对输出的说明：需要对照这一块最上面的蓝色解说</h4>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>标签编码：根据位置，为制定一个数字标签，用于提供给基于数值算法的数学模型</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        按照顺序给一些文字的特征赋值，每一列一个标签编码和对象；<br>
        # 获取标签编码器：<br>
        lbe = sp.LabelEncoder()<br>
        #调用标签编码器的fit_transform方法训练并且为原始样本进行标签编码<br>
        result = lbe.fit_transform(原始样本特征数组)<br>
        # 根据标签编码结果矩阵反查字典，得到原始数据矩阵<br>
        samples = lbe.inverse_transform(result)<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import sklearn.preprocessing as sp<br>
        raw_samples = np.array(['audi','ford','audi','toyota','ford','bmw','ford','redflag','audi'])<br>
        print(raw_samples)<br>
        lbe = sp.LabelEncoder()<br>
        result = lbe.fit_transform(raw_samples)<br>
        print(result)<br>
        test = [0,0,1,1,4]<br>
        print(lbe.inverse_transform(test)) # 转换成开始的定义<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>线性回归（1）：</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        预测函数， y = f(x)<br>
        所谓模型训练，就是根据已知的x和y，找到最佳的模型参数w0和w1，尽可能精确地描述输入和输出的关系<br>
        单样本误差： 根据预测函数求出输入为x时的预测值：y' = w0 + w1x，单样本误差为1/2(y'-y)^2。<br>
        总样本误差： 单样本误差的和<br>
        损失函数： loss = 1/2(w0 + w1x -y)^2 （这里1/2只是为了计算方便）<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例（损失函数）</h4>
        import numpy as np<br>
        import matplotlib.pyplot as mp<br>
        <br>
        xs = np.array([0.5, 0.6, 0.8, 1.1, 1.4])<br>
        ys = np.array([5.0, 5.5, 6.0, 6.8, 7.0])<br>
        n = 500<br>
        w0_grid,w1_grid = np.meshgrid(np.linspace(-10, 10, n),np.linspace(-10, 10, n))<br>
        loss = 0<br>
        for x,y in zip(xs,ys):<br>
        loss += (w0_grid + w1_grid * x - y)**2 / 2<br>
        <br>
        # 画图：<br>
        fig = mp.figure('Loss Function', facecolor='lightgray')<br>
        ax3d = fig.add_subplot(projection='3d')<br>
        ax3d.set_xlabel('w0')<br>
        ax3d.set_ylabel('w1')<br>
        ax3d.set_zlabel('loss')<br>
        ax3d.plot_surface(w0_grid, w1_grid, loss, cstride=30, rstride=30, cmap='jet')<br>
        mp.tight_layout()<br>
        mp.show()  # 图中要找到损失函数的最低点，可以试试两个偏导<br>

        <h4>&emsp;举例（梯度下降）</h4>
        import numpy as np<br>
        import matplotlib.pyplot as mp<br>
        
        train_x = np.array([0.5, 0.6, 0.8, 1.1, 1.4])<br>
        train_y = np.array([5.0, 5.5, 6.0, 6.8, 7.0])<br>
        
        w0, w1, epoches = [1], [1], []<br>
        times = 1000 #梯度下降次数<br>
        lrate = 0.01 #learning rate<br>
        losses = []<br>
        for i in range(1, times + 1):<br>
        epoches.append(i)<br>
        #求损失值<br>
        loss = ((w0[-1] + w1[-1] * train_x - train_y)**2).sum()<br>
        losses.append(loss)<br>
        print('{:4}> w0={:.8f}, w1={:.8f}, loss={:.8f}'.format(i,w0[-1],w1[-1],loss))<br>
        #求损失函数关于w0,w1的偏导数，更新模型参数<br>
        d0 = (w0[-1] + w1[-1] * train_x - train_y).sum()<br>
        d1 = (train_x * (w0[-1] + w1[-1] * train_x - train_y)).sum()<br>
        #梯度下降公式<br>
        w0.append(w0[-1] - lrate * d0)<br>
        w1.append(w1[-1] - lrate * d1)<br>
        print("w0:",w0[-1])<br>
        print("w1:",w1[-1]) # y = w0 + w1 * x<br>
        #绘制回归线<br>
        linex = np.linspace(train_x.min(), train_x.max(), 100)<br>
        liney = w1[-1] * linex + w0[-1]<br>
        <br>
        #画图：<br>
        mp.figure('Linear Regression', facecolor='lightgray')<br>
        mp.title('Linear Regression', fontsize = 18)<br>
        mp.grid(linestyle=":")<br>
        mp.scatter(train_x, train_y, s=80, marker='o', color='dodgerblue',label='Samples')<br>
        mp.plot(linex, liney, color='orangered', linewidth=2, <br>label='Regression Line')<br>
        mp.legend() #图例<br>
        <br>
        # 训练过程图，看到训练次数的上限：<br>
        mp.figure('training progress', facecolor='lightgray')<br>
        mp.title('Training Progress',fontsize=18)<br>
        mp.subplot(311) # 3行1列第一幅<br>
        mp.grid(linestyle=':')<br>
        mp.plot(epoches, w0[:-1], color='dodgerblue', label=r'$w_0$')<br>
        mp.legend()<br>
        <br>
        mp.subplot(312) # 3行1列第一幅<br>
        mp.grid(linestyle=':')<br>
        mp.plot(epoches, w1[:-1], color='dodgerblue', label=r'$w_1$')<br>
        mp.legend()<br>
        mp.tight_layout()<br>
        <br>
        mp.subplot(313) # 3行1列第一幅<br>
        mp.grid(linestyle=':')<br>
        mp.plot(epoches, losses, color='orangered', label=r'$loss$')<br>
        mp.legend()<br>
        mp.tight_layout()<br>
        <br>
        mp.show()<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>线性回归（2）API：</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        import sklearn.linear_model as lm<br>
        # 创建模型<br>
        model = lm.LinearRegression()<br>
        # 训练模型<br>
        # 输入为一个二维数组表示的样本矩阵<br>
        # 输出为每个样本最终的结果<br>
        model.fit(input, output) <br>
        # input是一个m*n的矩阵，output是一个m*1的矩阵<br>
        # 预测输出<br>
        # 输入array是一个二维数组，<b>每一行一个样本，每一列是一个特征</b><br>
        result = model.predict(array)<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import matplotlib.pyplot as mp<br>
        import sklearn.linear_model as lm<br>
        <br>
        # 采集数据 读取文本 整理输入（二维）输出（一维） 构建线性回归模型，训练，返回结果<br>
        x,y = np.loadtxt('name_of_file',delimiter=',',unpack=True)<br>
        x = x.reshape(-1,1) # 变成n行一列<br>
        mp.figure('Linear Regression', facecolor='lightgray')<br>
        mp.title('Linear Regression', fontsize=18)<br>
        mp.grid(linestyle=":")<br>
        mp.scatter(x, y, s=70, color='dodgerblue', label= 'Sample Points')<br>
        <br>
        model = lm.LinearRegression()<br>
        model.fit(x,y)<br>
        pred_y = model.predict(x)<br>
        mp.plot(x, pred_y, color='orangered', label='Regression Line')<br>
        <br>
        mp.legend()<br>
        mp.show()<br>
        <br>
        # 评估训练结果的误差（metrics）：<br>
        import sklearn.meyrics as sm<br>
        # 平均绝对值误差: (|实际输出-预测输出|.mean())<br>
        sm.mean_absolute_error(y, pred_y)<br>
        # 平均平方误差:sqrt((|实际输出-预测输出|^2.mean()))<br>
        sm.mean_squard_error(y, pred_y)<br>
        # 中位绝对值误差<br>
        sm.median_absolute_error(y, pred_y)<br>
        # R^2<br>
        sm.r2_score(y, pred_y)<br>
        # 用print进行输出<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>岭回归(LASSO)</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        当存在异常样本的时候，给损失函数加正则项，限制模型参数对异常样本的匹配程度<br>
        import sklearn.linear_model as lm<br>
        # 创建模型<br>
        model = lm.Ridge(正则强度（需要调参！）,fit_intercept=是否训练拮据,
        max_iter=最大迭代次数（通过loss函数判断）)<br>
        # 训练模型<br>
        # 训练一个二维数组表示的样本矩阵<br>
        # 输出为每个样本最终的结果<br>
        model.fit(输入，输出)<br>
        # 预测输出<br>
        # 输入array是一个二维数组，每一行一个样本，一列一个特征<br>
        result = mdoel.predict(array)<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import matplotlib.pyplot as mp<br>
        import sklearn.linear_model as lm<br>
        import sklearn.metrics as sm<br>
        <br>
        # 采集数据 读取文本 整理输入（二维）输出（一维） 构建线性回归模型，训练，返回结果<br>
        x,y = np.loadtxt('name_of_file',delimiter=',',unpack=True)<br>
        x = x.reshape(-1,1) # 变成n行一列<br>
        mp.figure('Ridge Regression', facecolor='lightgray')<br>
        mp.title('Ridge Regression', fontsize=18)<br>
        mp.grid(linestyle=":")<br>
        mp.scatter(x, y, s=70, color='dodgerblue', label= 'Sample Points')<br>
        <br>
        model = lm.Ridge(100,fit_intercept=True,max_iter=100)<br>
        # 第一项为0则和线性回归一样，太大那么忽略的合理值太多也不合适<br>
        model.fit(x,y)<br>
        pred_y = model.predict(x)<br>
        print(sm.r2_score(y, pred_y))<br>
        mp.plot(x, pred_y, color='orangered', label='Ridge')<br>
        <br>
        mp.legend()<br>
        mp.show()<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>多项式回归：（更好拟合，用多项式回归器）</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        import sklearn.pipeline as pl<br>
        import sklearn.preprocessing as sp<br>
        import sklearn.linear_model as lm<br>
        # 同样用LinearRegression模型对样本数据进行模型训练，扩展特征，让x^n记为自变量xn<br>
        model = pl.make_pipeline(sp.PolynomialFeatures(10),lm.LinearRegression())<br>
        # 前者是多项式特征扩展器，后一个是线性回归器<br>
        # 欠拟合：模型过于简单，无法给出足够高的预测精度<br>
        # 过拟合：模型复杂，训练数据精度高，测试数据精度低<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import matplotlib.pyplot as mp<br>
        import sklearn.linear_model as lm<br>
        import sklearn.pipeline as pl<br>
        import sklearn.preprocessing as sp<br>
        import sklearn.metrics as sm<br>
        <br>
        # 采集数据 读取文本 整理输入（二维）输<br>
        # 出（一维） 构建线性回归模型，训练，返回结果<br>
        x,y = np.loadtxt('name_of_file',delimiter=',',unpack=True)<br>
        x = x.reshape(-1,1) # 变成n行一列<br>
        mp.figure('Linear Regression', facecolor='lightgray')<br>
        mp.title('Linear Regression', fontsize=18)<br>
        mp.grid(linestyle=":")<br>
        mp.scatter(x, y, s=70, color='dodgerblue', label= 'Sample Points')<br>
        <br>
        model = pl.make_pipeline(sp.PolynomialFreatures(10),lm.LinearRegression())<br>
        model.fit(x,y)<br>
        pred_y = model.predict(x.reshape(-1,1)) #这里也是要一列，上面的linspace是一行<br>
        print(sm.median_absolute_error(y,pred_y))<br>
        print(sm.r2_score(y, pred_y))<br>
        # 预测500个函数结果，按顺序连线<br>
        x = np.linspace(x.min(),x.max(),500)<br>
        pred_y = model.predict(x)<br>
        mp.plot(x, pred_y, color='orangered')<br>
        <br>
        mp.legend()<br>
        mp.show()<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>决策树：相似输入产生相似输出</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        # 连续数据离散化，树的结构分类，随着子表的划分，那么就可以不断减少信息熵<br>
        # 工程优化：降低决策树层数，在精确度可以接受的情况下提高性能，优先选择减少信息熵作为划分子表的依据<br>
        # 允许混杂一些不同的特征值<br>
        <br>
        import sklearn.tree as st<br>
        #创建决策树回归模型，决定最大深度<br>
        model = st.DecisionTreeRegressor(max_depth=4)<br>
        #训练模型<br>
        # train_x :二维数组样本数据<br>
        # train_y :训练集中对应每行样本的结果<br>
        model.fit(train_x,train_y)<br>
        #测试模型<br>
        pred_text_y = model.predict(test_x)<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import sklearn.datasets as sd<br>
        import sklearn.utils as su<br>
        #加载波士顿地区的房价数据集（版本不支持，看B站视频
        https://www.bilibili.com/video/BV1a44y1J7xK）<br>
        boston = sd.load_boston()<br>
        print(boston.data.shape) # 输入数据<br>
        print(boston.target.shape) # 输出结果<br>
        print(boston.feature_names) # 输入数据的特征名<br>
        <br>
        # 打乱原始数据集，拆分训练集和测试集<br>
        # random_state:随机种子，使用相同的随机种子多次打乱得到的结果是一样的<br>
        x,y = su.shuffle(boston.data, boston.target, random_state = 7)<br>
        train_size = int(len(x) * 0.8)<br>
        train_x, test_x, train_y, test_y = \<br>
        x[:train_size],x[train_size:],y[:train_size],y[train_size:]<br>
        <br>
        # 构建决策树模型<br>
        import sklearn.tree as st<br>
        import sklearn.metrics as sm<br>
        model = st.DecisionTreeRegressor(max_depth=4)<br>
        model.fit(train_x,train_y)<br>
        pred_test_y = model.predict(test_x)<br>
        # 评估结果<br>
        r = sm.r2_score(test_y, pred_test_y)<br>
        print(r)<br>
        print(sm.median_absolute_error(test_y,pred_test_y))<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>集合算法：</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        # 根据多个模型给出的预测结果，利用平均或者投票的方法得出最后的预测结果（基于决策树）<br>
        # 正向激励：随机分配权重，提供预测输出的时候加权平均产生预测值<br>
        # 代入训练集对于差距大的样本形成第二棵决策树<br>
        import sklearn.tree as st<br>
        import sklearn.ensemble as se<br>
        # model：决策树模型<br>
        model = st.DecisionTreeRegressor(max_depth=4)<br>
        # 自适应增强决策树的回归模型<br>
        # n_estimators=400：构建400棵不同权重的决策树，训练模型<br>
        model = se.AdaBoostRegressor(model, n_estimators=400, random_state=7)<br>
        # 训练模型<br>
        model.fit(train_x,train_y)<br>
        # 测试模型<br>
        pred_test_y = model.predict(test_x)<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import sklearn.datasets as sd<br>
        import sklearn.utils as su<br>
        import sklearn.ensemble as se<br>
        #加载波士顿地区的房价数据集（版本不支持，看B站视频
        https://www.bilibili.com/video/BV1a44y1J7xK）<br>
        boston = sd.load_boston()<br>
        print(boston.data.shape) #输入数据<br>
        print(boston.target.shape) #输出结果<br>
        print(boston.feature_names) #输入数据的特征名<br>
        <br>
        #打乱原始数据集，拆分训练集和测试集<br>
        #random_state:随机种子，使用相同的随机种子多次打乱得到的结果是一样的<br>
        x,y = su.shuffle(boston.data, boston.target, random_state = 7)<br>
        train_size = int(len(x) * 0.8)<br>
        train_x, test_x, train_y, test_y = \<br>
        x[:train_size],x[train_size:],y[:train_size],y[train_size:]<br>
        <br>
        #构建决策树模型<br>
        import sklearn.tree as st<br>
        import sklearn.metrics as sm<br>
        model = st.DecisionTreeRegressor(max_depth=4)<br>
        model.fit(train_x,train_y)<br>
        pred_test_y = model.predict(test_x)<br>
        #评估结果<br>
        r = sm.r2_score(test_y, pred_test_y)<br>
        print(r)<br>
        print(sm.median_absolute_error(test_y,pred_test_y))<br>
        <br>
        se.AdaBoostRegressor(model, n_estimators=400, random_state=7)<br>
        #两个参数需要手动调参，第一个数量多时间长<br>
        model.fit(train_x,train_y)<br>
        pred_test_y = model.predict(test_x)<br>
        r = sm.r2_score(test_y,pred_test_y)<br>
        print(r)<br>
        print(sm.median_absolute_error(test_y,pred_test_y))<br>
        </p>
        <br>
        <h4>https://blog.csdn.net/weixin_42163563/article/details/131673800</h4>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>特征重要性：</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        获取样本矩阵特征重要性：<br>
        model.fit(train_x, train_y)<br>
        fi = model.feature_importances_<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        <b>接上集合算法的代码</b><br>
        <br>
        import matplotlib.pyplot as mp<br>
        mp.figure('Feature Importances',facecolor='lightgray')<br>
        mp.subplot(211)<br>
        mp.title('DT Feature Importances',fontsize=16)<br>
        mp.ylabel('Feature Importance',fontsize=14)<br>
        mp.grid(linestyle=":",axis=1)<br>
        x = np.arange(dt_fi.size)<br>
        mp.bar(x, dt_fi, 0.8, color='dodgerblue', lable='...')<br>
        # 对fi排序<br>
        sorted_induces = dt_fi.argsort()[::-1]<br>
        dt_fi = ada_fi[sorted_indices]<br>
        # x刻度线处理<br>
        mp.xticks(x, names[sorted_indices])<br>
        mp.legend()<br>
        mp.tight_layout()<br>
        mp.show()<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>自助聚合和随机森林</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        后者的效果更好所以一般就用随机森林，提高泛化特性<br>
        个人认为，集合算法是把在后续分类中，把偏差大的重新考虑一种分类方式，而随机森林只是为了让分类层数尽可能少。<br>
        <br>
        import sklearn.ensemble as se<br>
        # 随机森林回归模型<br>
        # max_depth:决策树最大深度为10<br>
        # n_estimators:构建1000棵决策树，训练模型<br>
        # min_sample_split:子表中最小样本数，小于该数字后不再继续向下拆分<br>
        model = se.RandomForestRegressor \<br>
        (max_depth=10, n_estimator=1000, min_samples_split=2)<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import sklearn.utils as su<br>
        import sklearn.ensemble as se<br>
        import sklearn.metrics as sm<br>
        import matplotlib.pyplot as mp<br>
        <br>
        data = []<br>
        with open('url_of file.csv','r') as f:<br>
        for line in f.readlines():<br>
        data.append(line[:-1].split(','))<br>
        print(data) #会把标题行也放进来，还有末尾一位的\n，所以有[:-1]<br>
        header = np.array(data[0][2:13]) #切位置<br>
        # data = np.array(data[1:][2:13])[:,2:13] #取有用数据<br>
        # data = data.astype('f8')<br>
        # print(header.shape, header.dtype)<br>
        # print(data.shape,data.dtype)<br>
        x = np.array(data[1:])[:,2:13].astype('f8')<br>
        y = np.array(data[1:])[:,-1].satype('f8')<br>
        # 打乱数据集，拆分训练集和测试集<br>
        su.shuffle(x, y, random_state=7)<br>
        train_size = int(len(x)*0.9)<br>
        train_x, test_x, train_y, test_y = \<br>
        x[:train_size], x[train_size:], \<br>
        y[:train_size], y[train_size:]<br>
        #训练随机森林模型：<br>
        model = se.RandomForestRegressor \<br>
        (max_depth=10, n_estimators=1000, min_samples_split=2)<br>
        model.fit(train_x,train_y)<br>
        #输出结果r2得分：<br>
        pred_test_y = model.predict(test_x)<br>
        print(sm.r2_score(test_y, pred_test_y))<br>
        day_fi = model.feature_importances_<br>
        #再补上特征重要性的可视化代码。(画图)<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>人工分类：</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        通过已知的模型，将数据进行分类，预测接下来一组数据是哪一类（离散的）。<br>
        这里就相当于用if……else……进行判断，比较简单<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import matplotlib.pyplot as mp<br>
        x = np.array([<br>
        [3,1],
        [2,5],
        [1,8],
        [6,4],
        [5,2],
        [3,5],
        [4,7],
        [4,-1]])
        y = np.array([0,1,1,0,0,1,1,0])<br>
        l, r = x[:,0].min() - 1, x[:,0].max() + 1<br>
        b, t = x[:,1].min() - 1, x[:,1].max() + 1<br>
        # l是第一列的最小值-1，r是第一列的最大值+1<br>
        # b是第二列的最小值-1，t是第二列的最大值+1 上下左右边界<br>
        # 绘制分类边界线：<br>
        n = 500<br>
        # 划分可视区间<br>
        grid_x, grid_y = np.meshgrid(np.linspace(l,r,n), np.linspace(b,t,n))<br>
        # 行数，列数各自拆成n份<br>
        grid_z = np.piecewise(grid_x, [grid_x > grid_y, grid_x < grid_y],[0, 1]) <br>
        # piecewise: 首先是传入grid_x,如果他服从第一个条件grid_x>grid_y，返回前者1，否则返回0<br>
        # 画图：<br>
        mp.figure('Simple Classification', facecolor='lightgray')<br>
        mp.title('Simple Classification', fontsize=16)<br>
        mp.xlabel('x',fontsize=14)<br>
        mp.ylabel('y',fontsize=14)<br>
        mp.tick_params(labelsize = 10)<br>
        mp.pcolormesh(grid_x, grid_y, grid_z, cmap='gray')<br>
        mp.scatter(x[:,0],x[:,1], c=y , cmap='brg' ,label='Sample points',s=80, zorder = 3)<br>
        # cmap是用颜色来区分的，具体用法可以借鉴网站：https://blog.csdn.net/weixin_39580795/article/details/102622004<br>
        # zorder是关于图层的显示顺序<br>
        mp.legend()<br>
        mp.show()<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>逻辑分类：</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        通过输入数据，基于多元线性回归模型求出线性预测方程（y = w0 + w1x1 + w2x2 ）<br>
        但是线性方程返回的是连续预测值，那么我们需要一个连续到离散的转换，<br>
        根据实数的稠密性，负无穷到正无穷可以一一对应到【0，1】区间 <br>
        逻辑函数 z = 1 / (1 + exp(-y))  z看作被划分为1类的概率     很重要！！！！<br>
        <br>
        bin = sp.Binarizer(threshold = 阈值)<br>
        # 调用transform方法对原始样本矩阵进行二值化预处理操作<br>
        result = bin.transform(原始图片样本转化的矩阵)<br>
            <br>
        import sklearn.linear_model as lm<br>
        model = lm.LogisticRegression(solver='liblinear', c=正则强度)<br>
        # solver：逻辑函数中指数的函数关系<br>
        # c：防止过拟合，正则越大拟合效果越小<br>
        model.fit(训练输入集，训练输出集)<br>
        result = model.predict(待预测输入集)<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import matplotlib.pyplot as mp<br>
        import sklearn.linear_model as lm<br>
        # 8个样本训练<br>
        x = np.array([<br>
            [3,1],<br>
            [2,5],<br>
            [1,8],<br>
            [6,4],<br>
            [5,2],<br>
            [3,5],<br>
            [4,7],<br>
            [4,-1]])<br>
        y = np.array([0,1,1,0,0,1,1,0])<br>
        model = lm.LogisticRegression(solver='liblinear',C=1)<br>
        model.fit(x,y)<br>
        x_test = []<br>
        for i in range(-50,50):<br>
            for j in range(-50,50):<br>
                x_test.append([i,j])<br>
        r = model.predict(x_test)<br>
        #经过检验，如果说和是偶数输出1，奇数输出0，逻辑回归不太能做到<br>
        <br>
        n = 500<br>
        # 划分可视区间<br>
        l, r = x[:,0].min() - 1, x[:,0].max() + 1<br>
        b, t = x[:,1].min() - 1, x[:,1].max() + 1<br>
        grid_x, grid_y = np.meshgrid(np.linspace(l,r,n), np.linspace(b,t,n))<br>
        mesh_x = np.column_stack([grid_x.ravel(), grid_y.ravel()])<br>
        # 列合并 250000*2<br>
        mesh_z = model.predict(mesh_x)<br>
        grid_z = mesh_z.reshape(grid_x.shape)<br>
        # 画图：<br>
        mp.figure('Simple Classification', facecolor='lightgray')<br>
        mp.title('Simple Classification', fontsize=16)<br>
        mp.xlabel('x',fontsize=14)<br>
        mp.ylabel('y',fontsize=14)<br>
        mp.tick_params(labelsize = 10)<br>
        mp.pcolormesh(grid_x, grid_y, grid_z, cmap='gray')<br>
        mp.scatter(x[:,0],x[:,1], c=y , cmap='brg' ,label='Sample points',s=80, zorder = 3)<br>
        # cmap是用颜色来区分的，具体用法可以借鉴网站：https://blog.csdn.net/weixin_39580795/article/details/102622004<br>
        # zorder是关于图层的显示顺序<br>
        mp.legend()<br>
        mp.show()<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>多元分类：</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        基于二元分类，训练出一个判断是否为A类别，在用同样方法看是不是B和C类别。<br>
        问题：那么如果还是上面那个公式，概率会不会差很多，先判断的类别，在这个集合中的概率大<br>
        下面代码会发现偏心严重，存在过拟合，对训练样本效果好，但是测试样本不好，所以参数C可以放大一点<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import matplotlib.pyplot as mp<br>
        import sklearn.linear_model as lm<br>
        # 8个样本训练<br>
        x = np.array([<br>
            [4,7],<br>
            [3.5,8],<br>
            [3.1,6.2],<br>
            [0.5,1],<br>
            [1,2],<br>
            [1.2,1.9],<br>
            [6,2],<br>
            [5.7,1.5],<br>
            [5.4,2.2]])<br>
        y = np.array([0,0,0,1,1,1,2,2,2])<br>
        model = lm.LogisticRegression(solver='liblinear',C=1)<br>
        model.fit(x,y)<br>
        x_test = []<br>
        for i in range(-50,50):<br>
            for j in range(-50,50):<br>
                x_test.append([i,j])<br>
        r = model.predict(x_test)<br>
        <br>

        n = 500<br>
        # 划分可视区间<br>
        l, r = x[:,0].min() - 1, x[:,0].max() + 1<br>
        b, t = x[:,1].min() - 1, x[:,1].max() + 1<br>
        grid_x, grid_y = np.meshgrid(np.linspace(l,r,n), np.linspace(b,t,n))<br>
        mesh_x = np.column_stack([grid_x.ravel(), grid_y.ravel()])<br>
        # 列合并 250000*2<br>
        mesh_z = model.predict(mesh_x)<br>
        grid_z = mesh_z.reshape(grid_x.shape)<br>
        # 画图：<br>
        mp.figure('Simple Classification', facecolor='lightgray')<br>
        mp.title('Simple Classification', fontsize=16)<br>
        mp.xlabel('x',fontsize=14)<br>
        mp.ylabel('y',fontsize=14)<br>
        mp.tick_params(labelsize = 10)<br>
        mp.pcolormesh(grid_x, grid_y, grid_z, cmap='gray')<br>
        mp.scatter(x[:,0],x[:,1], c=y , cmap='brg' ,label='Sample points',s=80, zorder = 3)<br>
        # cmap是用颜色来区分的，具体用法可以借鉴网站：https://blog.csdn.net/weixin_39580795/article/details/102622004<br>
        # zorder是关于图层的显示顺序<br>
        mp.legend()<br>
        mp.show()<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>朴素（特征值独立）贝叶斯分类（https://zhuanlan.zhihu.com/p/37575364）</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        依据统计概率理论实现的一种分类方式，整理相同特征值的样本，决策树的思想。取概率高的作为最后输出的类别。<br>
        和决策树的区别：<br>
        * 决策树的构建过程是递归的，通过选择最优特征和划分数据集来生成树。<br>
        * 决策树易于理解和解释，但容易过拟合。<br>
        * 贝叶斯分类是一种基于贝叶斯定理的分类方法，通过计算后验概率来进行分类。<br>
        * 贝叶斯分类假设特征之间相互独立，根据特征的条件概率计算后验概率，选择具有最大后验概率的类别作为分类结果。<br>
        <br>
        贝叶斯定理：P(A|B)=P(B|A)P(A)/P(B)，所以各个特征要独立[P(B|A) = 1/3]，所以少量数据不准<br>
        应用：P(A,B,C,D) = P(A|B,C,D) * P(B,C,D) = P(A|B,C,D) * P(B|C,D) * P(C,D)<br>
                        = P(A|B,C,D) * P(B|C,D) * P(C|D) * P(D)<br>
                        = 1/Z * P(A|D) * P(B|D) * P(C|D) * P(D)<br>
        <br>
        相关API：<br>
        # 创建高斯分布朴素贝叶斯分类器：<br>
        model = nb.GaussianNB()<br>
        model.fit(x,y)<br>
        result = model.predict(samples)<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        import numpy as np<br>
        import sklearn.naive_bayes as nb<br>
        import matplotlib.pyplot as mp<br>
        <br>
        data = np.loadtxt("bayes_eg.txt",delimiter=",")<br>
        x = data[:,:2].astype('f8')<br>
        y = data[:,-1].astype('f8')<br>
        print(x.shape, y.shape)<br>
        model = nb.GaussianNB()<br>
        model.fit(x,y)<br>
        # 划分可视区间<br>
        l, r = x[:,0].min() - 1, x[:,0].max() + 1<br>
        b, t = x[:,1].min() - 1, x[:,1].max() + 1<br>
        n = 500<br>
        grid_x, grid_y = np.meshgrid(np.linspace(l,r,n), np.linspace(b,t,n))<br>
        mesh_x = np.column_stack([grid_x.ravel(), grid_y.ravel()])<br>
        mesh_z = model.predict(mesh_x)<br>
        grid_z = mesh_z.reshape(grid_x.shape)<br>
        # 画图<br>
        mp.figure('Naive Bayes Classification', facecolor='lightgray')<br>
        mp.title('Naive Bayes Classification', fontsize=16)<br>
        mp.xlabel('x',fontsize=14)<br>
        mp.ylabel('y',fontsize=14)<br>
        mp.pcolormesh(grid_x, grid_y, grid_z, cmap='gray')<br>
        mp.scatter(x[:,0],x[:,1], c=y , cmap='brg' ,label='Sample points',s=80)<br>
        mp.show()<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>朴素贝叶斯分类——数据集划分</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        上面的txt数据，分布成训练集和测试集。但是分类不能随便拆数据。（没学不能硬要预测）<br>
        <br>
        相关API：<br>
        <br>
        import sklearn.model_selection as ms<br>
        train_x, test_x, train_y, test_y = 
                ms.train_test_split(input, output, 
                        test_size = 测试集占比, random_state = 随机种子)<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>朴素贝叶斯分类——交叉验证</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        数据划分具有不确定性，万一划分全在特殊样本上，则可信度遭受质疑。<br>
        所以先等分成n份，不同数据作为训练集交叉验证，<br>
        <br>
        相关API：<br>
        <br>
        import sklearn.model_selection as ms<br>
        指标值数组 = ms.cross_val_score(模型，输入集，输出集，
                                        cv=折叠数（交叉验证次数）,scoring = 指标名)<br>
                                    <br>
        指标名：accuracy:精确度 = 正确/总<br>
            precision_weighted:查准率 = 针对一个类类别， 预测正确/预测总样本<br>
            recall_weighted:召回率 = 针对一个类别预测正确/该类别实际存在总数<br>
            f1_weighted:f1得分 = 2 * precision_weighted * recall_weighted/<br>
                                    (precision_weighted + recall_weighted)<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>朴素贝叶斯分类——混淆矩阵</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        属于评估算法，行是类别，列是预测类别。<br>
        查准率 = 主对角线上值 / 该值所在列的和<br>
        召回率 = 主对角线上值 / 该值所在行的和<br>
        <br>
        相关API:<br>
        <br>
        import sklearn.metrics as sm<br>
        混淆矩阵 = sm.confusion_matrix(实际输出，预测输出)<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>朴素贝叶斯分类——分类报告（上述的集合）</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        import sklearn.metrics as sm<br>
        cr = sm.classification_report(实际输出，预测输出)<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>决策树分类</h3>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        回归——求均值；分类——投票<br>
        <br>
        例：小汽车分类——随机森林分类器<br>
        # 读取文本数据，对每一列进行标签编码<br>
        # 整理样本空间，输入集和输出集<br>
        <br>
        import numpy as np<br>
        import sklearn.preprocessing as sp    # 标签编码<br>
        import sklearn.ensemble as se    # 随机森林<br>
        import sklearn.model_selection as ms    # 交叉验证<br>
        <br>
        data = []<br>
        with open('决策树分类.txt','r') as f:<br>
            for line in f.readlines():<br>
                #注意不是readline而是readlines，read和readline是str类型，readlines是list类型<br>
                data.append(line[:-1].split(','))       # [:-1]是为了删掉最后的\n<br>
        data = np.array(data)<br>
        print(data.shape)<br>
        <br>
        train_x, train_y = [],[]<br>
        encoders = []   # 标签编码储存器<br>
        for index,row in enumerate(data.T):    # 遍历的时候增加一个下标<br>
            encoder = sp.LabelEncoder()<br>
            if index < (len(data.T)-1):    # 添加到输入集<br>
                train_x.append(encoder.fit_transform(row))<br>
            else:<br>
                train_y = encoder.fit_transform(row)<br>
            encoders.append(encoder)<br>
        <br>
        train_x = np.array(train_x).T<br>
        train_y = np.array(train_y)<br>
        <br>
        print(train_x.shape, train_y.shape)<br>
        # 训练随机森林分类器模型<br>
        model = se.RandomForestClassifier(max_depth=6, n_estimators=100, random_state=7)<br>
        score = ms.cross_val_score(model,train_x,train_y,cv=2,scoring='f1_weighted')<br>
        print(score.mean())<br>
        model.fit(train_x, train_y)<br>
        # 自定义测试数据，用训练好的模型测试<br>
        data = []<br>
        data = np.array(data)<br>
        test_x = []<br>
        test_y = []<br>
        for index,row in enumerate(data.T):    # 遍历的时候增加一个下标<br>
            encoder = encoders[index]<br>
            if index < (len(data.T) - 1):    # 添加到输入集<br>
                test_x.append(encoder.fit_transform(row))<br>
            else:<br>
                test_y = encoder.fit_transform(row)<br>
        test_x = np.array(test_x).T<br>
        test_y = np.array(test_y)<br>
        pred_test_y = model.predict(test_x)<br>
        print(encoder[-1].inverse_transform(test_y))<br>
        print(encoder[-1].inverse_transform(pred_test_y))<br>
        <br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>验证曲线：（调参）</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        验证曲线：模型性能 = f(超参数)，但同时也要考虑模型的简单程度，不完全是追求精确度最高<br>

        相关API：<br>
            train_scores, test_scores = ms.validation_curve(
                model,
                输入集， 输出集，
                'n_estimators'           # 超参数名（决策树棵数）
                np.arange(50,550,50)        # 超参数序列
                cv = 5      # 折叠数
                )<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        用上面小汽车案例：（可以去掉交叉验证，因为本身就是f1得分）<br>
        <br>
        import matplotlib.pyplot as mp<br>
        import sklearn.model_selection as ms<br>
        train_scores, test_scores = ms.validation_curve(model, train_x, train_y,
                            'n_estimator', np.arange(50,500,50),cv = 5)<br>
        print(test_scores.mean(axis=1))<br>
        mp.scatter(np.arange(50,500,50),test_scores.mean(axis=1))<br>
        mp.legend()<br>
        mp.show()<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>学习曲线：</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        学习曲线：模型性能 = f（训练集大小）<br>
        <br>
        相关API：<br>
        _, train_scores, test_scores = ms.learning_curve(    # 返回值有三个，但是第一个没用
            model,  # 模型
            输入集，输出集，
            train_sizes = [0.9,0.8,0.7]  # 训练集大小序列
            cv = 5  # 折叠数
            )<br>
        <br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例</h4>
        用上面小汽车案例：（在随机森林代码后面）<br>
        <br>
        import numpy as np<br>
        import matplotlib.pyplot as mp<br>
        import sklearn.model_selection as ms<br>
        ms.learning_curve(
            model,train_x,train_y,
            train_sizes=np.arange(0.1,1,0.1),
            cv = 5
            )<br>
        test_mean = test_scores.mean(axis=1)<br>
        <br>
        mp.grid(linestyle=':')<br>
        mp.scatter(train_sizes, test_mean)<br>
        mp.show()<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>支持向量机（SVM）</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        * 寻求最优分类边界：正确、泛化、公平、简单（线性） <br>
        最近两点做平行线，距离最远<br>
        * 基于核函数的升维变换（线性不可分，那么n维样本用n+1维分）<br>
        线性核函数，不通过核函数提升维度，仅在原始维度中寻求线性分类边界<br>
        多项式核函数：<br>
        径向基核函数：通过高斯分布增加原始样本特征的分布概率<br>
        举例：<br>
        序号  数据  自己造的特征（防止重合，如y = 2*x*x+3*x+4 ）  <br>
        1 0 x<br>
        2 0 x<br>
        3 1 x<br>
        4 1 x<br>
        5 0 x<br>
        6 0 x<br>
        <br>
        API：<br>
        <br>
        import sklearn.svm as svm<br>
        model = svm.SVC(kernal='linear')    <br>
                #或者kernal='poly',degree=3; 或者kernel=‘rbf’,C(正则)=600,gamma=0.01<br>
        model.fit(x,y)<br>
        pre_test_y = model.predict(test_x)<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>支持向量机——样本类别均衡化</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        通过类别权重的均衡化，让占比小的样本权重变高，平均化各类样本对分类模型的贡献，提高模型性能。 <br>
        样本不均衡可以用上采样和下采样的方法。<br>
        <br>
        相关API：<br>
        model = svm.SVC(kernel='linear',class_weight='balanced')<br>
        model.fit(train_x,train_y)<br>
        </p>
    </div>

    <div class="content" name="disableCopyPaste">
        <h3>支持向量机——置信概率</h3>
        <br>
        <p class="explain">
        <h4>&emsp;解说</h4>
        根据样本距离边界的远近，量化预测的可信程度，离边界越近，置信概率越低。<br>
        <br>
        API:<br>
        在获取模型的时候，给出超参数probability=True<br>
        model = svm.SVC(kernel='rbf', C=600, gamma=0.01, probability=True)<br>
        预测结果 = model.predict(输入样本矩阵)<br>
        调用model.predict_proba(样本矩阵)获取置信区间<br>
        </p>
        <br>
        <p class="code">
        <h4>&emsp;举例(续)</h4>
        import numpy as np<br>
        import matplotlib.pyplot as mp<br>
        prob_x = np.array([<br>
            [2,1.5],<br>
            [8,9],<br>
            [4.8,5.2]<br>
        ])<br>
        pred_prob_y = model.predict_proba(prob_x)<br>
        print(pred_prob_y)<br>
        mp.scatter(prob_x[:,0], prob_x[:,1], marker='D', c=pred_prob_y, cmap='jet_r', s=80)<br>
        for i in range(len(pred_prob_y)):<br>
            mp.annotate(
                '{}% {}%'.format(
                    round(pred_prob_y[i,0]*100,2),
                    round(pred_prob_y[1,1]*100,2)
                ),<br>&emsp;
                xy = (prob_x[i,0], prob_x[i,1]),
                xytext = (12,-12),
                textcoords = 'offset points',
                horizontalalognment = 'left',
                verticalalignment = 'left',
                fontsize = 9,<br>&emsp;
                bbox={'boxstyle':'round,pad=0.6',
                        'fc':'orange','alpha':0.8}
            )<br>
        </p>
    </div>

    <div class="content">
        <h1>后续关于ANN、CNN、RNN的代码由于没有备份，之后再补上</h1>
    </div>

    <script>
        window.onload = function ()
        {
            // 获取要禁用复制/粘贴的元素
            var element = document.getElementsByTagName("div");
            for (var i = 0; i < 100; i++)
            {
                element[i].oncopy = function ()
                {
                    return false;
                }

                element[i].onselectstart = function ()
                {
                    return false;
                }

                element[i].oncontextmenu = function ()
                {
                    return false;
                }
            }
        }
    </script>
</body>

</html>